{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMxHW5yPVQsG5Kxr0UJ3quj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x79bdrCwpCj5"},"outputs":[],"source":["!pip install tensorflow==2.10\n","!pip install mtcnn"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from mtcnn import MTCNN\n","import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IYyGV2-pMaW","executionInfo":{"status":"ok","timestamp":1667844909420,"user_tz":-480,"elapsed":4535,"user":{"displayName":"DL","userId":"13779012396429415859"}},"outputId":"cf87d44d-aa95-489b-8391-c011f215378d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.10.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htbC6RQUvEou","outputId":"4274cea3-f1a1-4135-f249-650471f07980","executionInfo":{"status":"ok","timestamp":1667843027890,"user_tz":-480,"elapsed":16958,"user":{"displayName":"DL","userId":"13779012396429415859"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"markdown","source":["### Define paths"],"metadata":{"id":"zT2HDP29qtZX"}},{"cell_type":"code","source":["IMAGE_HOME = './drive/MyDrive/data'\n","LABEL_HOME = './drive/MyDrive/data/label'\n","DS_HOME = './drive/MyDrive/data/saved_data'"],"metadata":{"id":"7SrhwnKhpeJw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encode features\n","- gender: 0/1\n","- age: one-hot encoding\n","- age_new: as discussed in the report, turn it into 8 binary classifications of 'is age of this image older than {age_class}'. For example, people in (8, 12) are also older than (4, 6), (0, 2), so vector would be `[[1],[1],[1],[0],[0],[0],[0],[0]]`"],"metadata":{"id":"0lBP-UTuqvh7"}},{"cell_type":"code","source":["GENDER_DICT = {'m': 0, 'f': 1}\n","AGE_DICT = {\n","    '(0, 2)': [1,0,0,0,0,0,0,0],\n","    '(4, 6)': [0,1,0,0,0,0,0,0],\n","    '(8, 12)': [0,0,1,0,0,0,0,0],\n","    '(15, 20)': [0,0,0,1,0,0,0,0],\n","    '(25, 32)': [0,0,0,0,1,0,0,0],\n","    '(38, 43)': [0,0,0,0,0,1,0,0],\n","    '(48, 53)': [0,0,0,0,0,0,1,0],\n","    '(60, 100)': [0,0,0,0,0,0,0,1],\n","}\n","AGE_DICT_NEW = {\n","    '(0, 2)': [[1],[0],[0],[0],[0],[0],[0],[0]],\n","    '(4, 6)': [[1],[1],[0],[0],[0],[0],[0],[0]],\n","    '(8, 12)': [[1],[1],[1],[0],[0],[0],[0],[0]],\n","    '(15, 20)': [[1],[1],[1],[1],[0],[0],[0],[0]],\n","    '(25, 32)': [[1],[1],[1],[1],[1],[0],[0],[0]],\n","    '(38, 43)': [[1],[1],[1],[1],[1],[1],[0],[0]],\n","    '(48, 53)': [[1],[1],[1],[1],[1],[1],[1],[0]],\n","    '(60, 100)': [[1],[1],[1],[1],[1],[1],[1],[1]],\n","}"],"metadata":{"id":"w5jP4YhZpf4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_label(gender, age):\n","  return GENDER_DICT.get(gender), AGE_DICT.get(age)"],"metadata":{"id":"xGR6RWwp6kuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_label_new(gender, age):\n","  return GENDER_DICT.get(gender), AGE_DICT_NEW.get(age)"],"metadata":{"id":"I-IXLc0yaOFU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Some age labels are wrong, correct them by classifying them to adjacent class"],"metadata":{"id":"YN4EvwpFt6Yl"}},{"cell_type":"code","source":["def update_labels():\n","  for i in range(5):\n","    fname = 'fold_frontal_'+str(i)+'_data.txt'\n","    fpath = os.path.join(LABEL_HOME, fname)\n","    df = pd.read_csv(fpath, sep = '\\t')\n","    df.loc[df['age'] == '(8, 23)', 'age'] = '(8, 12)'\n","    df.loc[df['age'] == '(38, 42)', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '(38, 48)', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '(27, 32)', 'age'] = '(25, 32)'\n","    df.loc[df['age'] == '32', 'age'] = '(25, 32)'\n","    df.loc[df['age'] == '46', 'age'] = '(48, 53)'\n","    df.loc[df['age'] == '42', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '34', 'age'] = '(25, 32)'\n","    df.loc[df['age'] == '29', 'age'] = '(25, 32)'\n","    df.loc[df['age'] == '2', 'age'] = '(0, 2)'\n","    df.loc[df['age'] == '56', 'age'] = '(48, 53)'\n","    df.loc[df['age'] == '57', 'age'] = '(60, 100)'\n","    df.loc[df['age'] == '23', 'age'] = '(25, 32)'\n","    df.loc[df['age'] == '36', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '45', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '13', 'age'] = '(8, 12)'\n","    df.loc[df['age'] == '22', 'age'] = '(15, 20)'\n","    df.loc[df['age'] == '58', 'age'] = '(60, 100)'\n","    df.loc[df['age'] == '55', 'age'] = '(60, 100)'\n","    df.loc[df['age'] == '35', 'age'] = '(38, 43)'\n","    df.loc[df['age'] == '3', 'age'] = '(0, 2)'\n","    new_fname = 'fold_frontal_'+str(i)+'_update.txt'\n","    new_fpath = os.path.join(LABEL_HOME, new_fname)\n","    df.to_csv(new_fpath, sep='\\t', index=False)"],"metadata":{"id":"jPwZteP6anyl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Process image:\n","- We use MTCNN to crop images to the person's face only\n","- Then resize it to required size ([224, 224] for ResNet34)\n","- Then normalize it by pixel/255"],"metadata":{"id":"BHNuC_j5urnA"}},{"cell_type":"code","source":["def process_img(path, required_size=(224, 224)):\n","  pixels = plt.imread(path)\n","  detector = MTCNN()\n","  # detect face inside a box\n","  results = detector.detect_faces(pixels) \n","  # if a face is detected\n","  if len(results) > 0:\n","    # get face bounding box\n","    x1, y1, width, height = results[0]['box'] \n","    x2, y2 = x1 + width, y1 + height\n","    face = pixels[y1:y2, x1:x2]\n","\n","    image = Image.fromarray(face)\n","    image = image.resize(required_size) # resize to 224,224 because the model requires it to be that way \n","    image.save(path[:-4]+'_cropped.jpg') # rename it to 'old_name_crop.jpg'\n","    face_array = np.asarray(image)\n","    return face_array/255 # normalize it\n","  else:\n","    return None"],"metadata":{"id":"E70vvco9VTQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# when create new dataset with new age encoding, directly used the cropped images hence only need to normalize it\n","def process_img_new(path, required_size=(224, 224)):\n","  return plt.imread(path)/255"],"metadata":{"id":"eX6RFiUNGeN3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create dataset for each fold"],"metadata":{"id":"35VdEQORvLPf"}},{"cell_type":"code","source":["def read_save():\n","  for i in range(1, 5):\n","    fold_X = []\n","    fold_gender = []\n","    fold_age = []\n","\n","    # read each fold's images and labels information\n","    f_name = 'fold_frontal_' + str(i) + '_update.txt'\n","    f = os.path.join(LABEL_HOME, f_name)\n","    df = pd.read_csv(f, sep='\\t')\n","\n","    # for each row (image), process image, encode age and gender\n","    for index, row in df.iterrows():\n","      # find image\n","      image_name = 'landmark_aligned_face.' + str(row['face_id']) + '.' + row['original_image']\n","      image_path = os.path.join(IMAGE_HOME, row['user_id'], image_name)\n","\n","      # process image\n","      image = process_img(image_path)\n","\n","      # encode age and gender\n","      gender, age = encode_label(row['gender'], row['age'])\n","\n","      # ignore this image since label might be wrong or no face detected\n","      if gender is None or age is None or image is None: \n","        continue\n","\n","      fold_X.append(image)\n","      fold_gender.append(gender)\n","      fold_age.append(age)\n","    \n","    # combine all within this fold and save as tf dataset\n","    fold_X = tf.convert_to_tensor(fold_X)\n","    fold_gender = tf.convert_to_tensor(fold_gender)\n","    fold_age = tf.convert_to_tensor(fold_age)\n","    path = os.path.join(DS_HOME, 'cv_fold'+str(i))\n","    ds = tf.data.Dataset.from_tensor_slices((fold_X, {'gender_output': fold_gender, 'age_output': fold_age}))\n","    tf.data.Dataset.save(ds, path)"],"metadata":{"id":"0wBSi99qp7_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_save_new():\n","  for i in range(1,5):\n","    fold_X = []\n","    fold_gender = []\n","    fold_age = []\n","\n","    # read each fold's images and labels information\n","    f_name = 'fold_frontal_' + str(i) + '_update.txt'\n","    f = os.path.join(LABEL_HOME, f_name)\n","    df = pd.read_csv(f, sep='\\t')\n","\n","    # for each row (image), process image, encode age and gender\n","    for index, row in df.iterrows():\n","      # find image\n","      image_name = 'landmark_aligned_face.' + str(row['face_id']) + '.' + row['original_image']\n","      image_path = os.path.join(IMAGE_HOME, row['user_id'], image_name[:-4]+'_cropped.jpg')\n","\n","      # process image\n","      # some images don't have faces detected by MTCNN and hence don't have the cropped image. Add condition check to skip them\n","      if os.path.exists(image_path):\n","        image = process_img_new(image_path)\n","      else:\n","        image = None\n","        \n","      # encode age and gender\n","      gender, age = encode_label_new(row['gender'], row['age'])\n","\n","      # ignore this image since label might be wrong or no face detected\n","      if gender is None or age is None or image is None:\n","        continue\n","        \n","      fold_X.append(image)\n","      fold_gender.append(gender)\n","      fold_age.append(age)\n","    \n","    # combine all within this fold and save as tf dataset\n","    fold_X = tf.convert_to_tensor(fold_X)\n","    fold_gender = tf.convert_to_tensor(fold_gender)\n","    fold_age = tf.convert_to_tensor(fold_age)\n","    path = os.path.join(DS_HOME, 'cv_fold'+str(i)+'_new')\n","\n","    '''\n","    fold_age = [[[1],[0],[0],[0],[0],[0],[0],[0]], # age encoding for first example\n","                [[1],[1],[0],[0],[0],[0],[0],[0]], # age encoding for second example\n","                ...]\n","    hence, first column is label for 'age_group1'\n","    '''\n","    ds = tf.data.Dataset.from_tensor_slices((fold_X, {'gender_output': fold_gender, \n","                                                      'age_group1': fold_age[:, 0],\n","                                                      'age_group2': fold_age[:, 1],\n","                                                      'age_group3': fold_age[:, 2],\n","                                                      'age_group4': fold_age[:, 3],\n","                                                      'age_group5': fold_age[:, 4],\n","                                                      'age_group6': fold_age[:, 5],\n","                                                      'age_group7': fold_age[:, 6],\n","                                                      'age_group8': fold_age[:, 7],}))\n","    tf.data.Dataset.save(ds, path)"],"metadata":{"id":"IAAaBsGJLel3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["update_labels()"],"metadata":{"id":"q9VlYOKHwADK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["read_save()"],"metadata":{"id":"FDBV4qfJp-IT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["read_save_new()"],"metadata":{"id":"-T60Lj-1jt9s"},"execution_count":null,"outputs":[]}]}